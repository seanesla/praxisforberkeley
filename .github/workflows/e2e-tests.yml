name: E2E Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test-suite:
        description: 'Test suite to run'
        required: true
        default: 'smoke'
        type: choice
        options:
          - smoke
          - critical
          - full
          - performance
          - mobile
          - accessibility

env:
  NODE_VERSION: '18'
  PLAYWRIGHT_VERSION: '1.40.0'

jobs:
  # Job to determine which tests to run
  test-matrix:
    name: Determine Test Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Set test matrix
        id: set-matrix
        run: |
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "matrix={\"project\":[\"chromium\",\"firefox\",\"webkit\",\"mobile-chrome\",\"mobile-safari\"]}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            case "${{ github.event.inputs.test-suite }}" in
              "performance")
                echo "matrix={\"project\":[\"performance\"]}" >> $GITHUB_OUTPUT
                ;;
              "mobile")
                echo "matrix={\"project\":[\"mobile-chrome\",\"mobile-safari\"]}" >> $GITHUB_OUTPUT
                ;;
              "accessibility")
                echo "matrix={\"project\":[\"a11y\"]}" >> $GITHUB_OUTPUT
                ;;
              "full")
                echo "matrix={\"project\":[\"chromium\",\"firefox\",\"webkit\"]}" >> $GITHUB_OUTPUT
                ;;
              *)
                echo "matrix={\"project\":[\"chromium\"]}" >> $GITHUB_OUTPUT
                ;;
            esac
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "matrix={\"project\":[\"chromium\"]}" >> $GITHUB_OUTPUT
          else
            echo "matrix={\"project\":[\"chromium\",\"firefox\"]}" >> $GITHUB_OUTPUT
          fi

  # Main E2E test job
  e2e-tests:
    name: E2E Tests - ${{ matrix.project }}
    runs-on: ubuntu-latest
    needs: test-matrix
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.test-matrix.outputs.matrix) }}
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: praxis_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            node_modules
            */node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Install dependencies
        run: |
          npm ci
          cd backend && npm ci
          cd ../frontend && npm ci

      - name: Install Playwright browsers
        run: |
          cd frontend
          npx playwright install --with-deps ${{ matrix.project }}

      - name: Setup test database
        env:
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/praxis_test
        run: |
          cd backend
          npm run db:migrate
          npm run db:seed:test

      - name: Build applications
        run: |
          cd backend && npm run build
          cd ../frontend && npm run build
        env:
          NEXT_PUBLIC_API_URL: http://localhost:3001
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/praxis_test

      - name: Run E2E tests
        run: |
          cd frontend
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            npm run test:pr -- --project=${{ matrix.project }}
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            npm run test:nightly -- --project=${{ matrix.project }}
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            case "${{ github.event.inputs.test-suite }}" in
              "smoke")
                npm run test:e2e:smoke -- --project=${{ matrix.project }}
                ;;
              "critical")
                npm run test:e2e:critical -- --project=${{ matrix.project }}
                ;;
              *)
                npm run test:e2e:improved -- --project=${{ matrix.project }}
                ;;
            esac
          else
            npm run test:e2e:improved -- --project=${{ matrix.project }}
          fi
        env:
          CI: true
          BASE_URL: http://localhost:3000
          API_URL: http://localhost:3001
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/praxis_test
          TEST_DATABASE_URL: postgresql://testuser:testpass@localhost:5432/praxis_test
          JWT_SECRET: test-jwt-secret
          SKIP_AUTH_SETUP: false

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ matrix.project }}
          path: |
            frontend/test-results/
            frontend/playwright-report/
          retention-days: 7

      - name: Upload screenshots
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: screenshots-${{ matrix.project }}
          path: frontend/screenshots/
          retention-days: 7

      - name: Upload performance report
        if: matrix.project == 'performance'
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: |
            frontend/test-results/performance-report.json
            frontend/test-results/performance-violations.json
          retention-days: 30

  # Merge test reports
  merge-reports:
    name: Merge Test Reports
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download all test results
        uses: actions/download-artifact@v3
        with:
          path: all-results

      - name: Merge reports
        run: |
          cd frontend
          npx playwright merge-reports --reporter=html,github all-results/test-results-*

      - name: Upload merged report
        uses: actions/upload-artifact@v3
        with:
          name: playwright-report-merged
          path: frontend/playwright-report/
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Read test summary
            let summary = '## E2E Test Results\n\n';
            
            try {
              const results = JSON.parse(
                fs.readFileSync('frontend/test-results/summary.json', 'utf8')
              );
              
              summary += `✅ **Passed:** ${results.passed}\n`;
              summary += `❌ **Failed:** ${results.failed}\n`;
              summary += `⏭️ **Skipped:** ${results.skipped}\n`;
              summary += `⏱️ **Duration:** ${(results.duration / 1000).toFixed(2)}s\n\n`;
              
              if (results.failedTests.length > 0) {
                summary += '### Failed Tests\n';
                results.failedTests.forEach(test => {
                  summary += `- ${test.title}\n`;
                });
              }
              
              // Add performance summary if available
              if (fs.existsSync('frontend/test-results/performance-report.json')) {
                const perf = JSON.parse(
                  fs.readFileSync('frontend/test-results/performance-report.json', 'utf8')
                );
                summary += '\n### Performance Metrics\n';
                summary += `- Average Page Load: ${perf.stats.performanceMetrics.pageLoad?.toFixed(0) || 'N/A'}ms\n`;
                summary += `- Average API Response: ${perf.stats.performanceMetrics.apiResponse?.toFixed(0) || 'N/A'}ms\n`;
              }
              
            } catch (error) {
              summary += 'Could not load test results.\n';
            }
            
            // Find and update or create comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && comment.body.includes('E2E Test Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: summary
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: summary
              });
            }

  # Performance tracking job
  track-performance:
    name: Track Performance Trends
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: always() && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download performance reports
        uses: actions/download-artifact@v3
        with:
          name: performance-report
          path: performance-data

      - name: Update performance baseline
        if: success()
        run: |
          # This would typically push to a metrics service
          echo "Performance data collected"
          
      - name: Alert on performance regression
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Performance Regression Detected',
              body: 'E2E tests detected performance regressions. Check the latest test run for details.',
              labels: ['performance', 'regression']
            });